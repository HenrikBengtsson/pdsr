# Timing & Profiling {#profiling}

```{r echo = FALSE}
knitr::opts_chunk$set(fig.width = 5, fig.height = 5,
                      comment = NA, cache = TRUE) 
options(rt.theme = "lightgrid")
options(rt.fit.theme = "lightgrid")
```

```{r, comment="", results="asis", echo=FALSE}
old.hooks <- fansi::set_knit_hooks(knitr::knit_hooks)
options(crayon.enabled = TRUE)
```

Profiling your code involves timing the execution of different steps of a program. This is usually performed in order to identify bottlenecks that slow down the execution of your code and it helps you prioritize which parts to optimize. A 

## Time the execution of an expression with `system.time`

If you want to time how long it takes for an R expression to complete, you can use the base command `system.time`.  
"elapsed" time is real time in seconds. "user" and "system" are time used by the CPU on different types of tasks (see `?proc.time`)

```{r}
x <- rnorm(9999)
system.time({
    y <- vector("numeric", 9999)
    for (i in 1:9999) y[i] <- x[i]^3
})
```

```{r}
system.time(x^3)
```

You can use `replicate()` to get a measure of time over multiple executions and average it:

```{r}
library(mgcv)
library(glmnet)
set.seed(2020)
x <- replicate(100, rnorm(5000))
y <- x[, 1]^2 + x[, 5]^3 + 12 + rnorm(5000)
dat <- data.frame(x, y)
fit.glm <- function(dat) mod <- glm(y ~ x, family = gaussian, data = dat)
fit.gam <- function(dat) mod <- gam(y ~ x, family = gaussian, data = dat)
    
system.time(replicate(1000, fit.glm))
system.time(replicate(1000, fit.gam))
```

## Compare execution times of different expressions with `microbenchmark()`

`microbenchmark()` allows you to time the execution of multiple expressions with sub-millisecond accuracy. It will execute each command a number of times as defined by the `times` argument (default = 100), and output statistics of execution time per expression in nanoseconds. Using `plot()` on the output produces a boxplot comparing the time distributions.


```{r}
library(microbenchmark)
```

To start, we compare two very simple and fast operations, using base and dplyr to add two columns of 1000 integers:

```{r warning=FALSE}
dat <- as.data.frame(matrix(1:2000, 1000))
dim(dat)
library(dplyr)
```

```{r}
add2k <- microbenchmark(
  base = dat$V1 + dat$V2,
  dplyr = mutate(dat, a = V1 + V2))
```

You can print microbenchmark's output:

```{r}
add2k
```

and plot it:

```{r}
plot(add2k)
```

Now let's use the **nycflights13** dataset which includes data on 336776 flights that departed from any of the three NY area airports in 2013. Because the data comes as a [tibble](https://tibble.tidyverse.org/), we shall perform all operations on the tibble and a data.frame of the same data to compare.

```{r}
library(nycflights13)
class(flights)
dim(flights)
flightsDF <- as.data.frame(flights)
```

Compare performance base R vs. dplyr in calculating mean arrival delay by carrier using either a data.frame or a tibble:

```{r warning=FALSE}
dbc <- microbenchmark(
  df_aggregate = aggregate(flightsDF$arr_delay, by = list(flightsDF$carrier), mean, na.rm = TRUE),
  tb_aggregate = aggregate(flights$arr_delay, by = list(flights$carrier), mean, na.rm = TRUE),
  df_tapply = tapply(flightsDF$arr_delay, flightsDF$carrier, mean, na.rm = TRUE),
  tb_tapply = tapply(flights$arr_delay, flights$carrier, mean, na.rm = TRUE),
  df_dplyr = flightsDF %>% group_by(carrier) %>% summarize(mean(arr_delay, na.rm = TRUE)),
  tb_dplyr = flights %>% group_by(carrier) %>% summarize(mean(arr_delay, na.rm = TRUE)))
dbc
```

```{r}
plot(dbc)
```

```{r warning=FALSE}
library(rpart)
data(Sonar, package = "mlbench")

glmVSrpart <- microbenchmark(
  glm = glm(Class ~ ., family = "binomial", Sonar),
  rpart = rpart(Class ~ ., Sonar, method = "class"),
  times = 50)

plot(glmVSrpart)
```

## Profile a function with `profvis()`

`profvis` provides an interactive output to visualize how much time is spent in different calls within an algorithm.

```{r}
library(profvis)
library(rtemis)
data(Sonar, package = 'mlbench')
```

```{r}
profvis(rpart::rpart(Class ~ ., Sonar))
```
