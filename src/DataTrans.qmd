# Data Transformations {#datatrans}

```{r echo = FALSE}
knitr::opts_chunk$set(comment = NA, cache = TRUE) 
options(rt.theme = "whitegrid")
options(rt.fit.theme = "whitegrid")
options(rt.font = "sans")
```

```{r, comment="", results="asis", echo=FALSE}
old.hooks <- fansi::set_knit_hooks(knitr::knit_hooks)
options(crayon.enabled = TRUE)
```

```{r}
#| echo: false
suppressPackageStartupMessages(library(rtemis))
```

## Continuous variables

### Standardization / Scaling & Centering with `scale()` {#zscore}

**Scaling** of a numeric vector is achieved by elementwise division with the standard deviation. A scaled vector therefore has standard deviation equal to 1.

**Centering** of a numeric vector is achieved by elementwise subtraction of its mean. A centered vector therefore has mean equal to 0.

**Standardizing**, a.k.a. converting to Z-scores, involves scaling and centering. Scaling and centering is performed in R with the `scale()` function.

Depending on your modeling needs / the algorithms you plan to use, it is often important to scale and/or center your data. Note that many functions, but not all, may automatically scale and center data internally if it is required by the algorithm. Check the function documentation to see if you should manually scale or not.

`scale()` can be applied to a single vector or a matrix/data.frame.
In the case of a matrix or data.frame, scaling is applied on each column individually.
By default, both arguments `scale` and `center` are set to `TRUE`.

Scale a vector:

```{r}
head(iris$Sepal.Length)
Petal.Length_scaled <- scale(iris$Petal.Length)
head(Petal.Length_scaled)
```

Scale multiple columns of a matrix/data.frame:

```{r}
iris.scaled <- scale(iris[, -5])
head(iris.scaled)
```

First, let's verify that `scale()` did what we wanted:  

```{r}
colMeans(iris.scaled)
```

```{r}
apply(iris.scaled, 2, sd)
```

We got effectively 0 mean and standard deviation of 1 for each column.  

`scale()` outputs the scaled vector(s) along with the scaling and/or centering parameters saved as attributes in the output.

Note that in both cases, whether a vector input or data.frame, the output is a **matrix**:

```{r}
class(Petal.Length_scaled)
class(iris.scaled)
```

Get the output attributes:

```{r}
attributes(Petal.Length_scaled)
```

`center` is the mean:

```{r}
mean(iris$Petal.Length)
```

`scale` is the standard deviation:

```{r}
sd(iris$Petal.Length)
```

For a matrix/data.frame input, you get `center` and `scale` attributes per column:

```{r}
attributes(iris.scaled)
```

Let's save the scale and center attributes and then double check the calculations:

```{r}
.center <- attr(iris.scaled, "scaled:center")
.center
.scale <- attr(iris.scaled, "scaled:scale")
.scale
Sepal.Length_scaled <- (iris$Sepal.Length - .center[1]) / .scale[1]
all(Sepal.Length_scaled == iris.scaled[, "Sepal.Length"])
```

Note: Due to limitation in numerical precision, checking sets of floats for 
equality after multiple operations is 

```{r}
all.equal(Sepal.Length_scaled, iris.scaled[, "Sepal.Length"])
```

::: callout-note
If you are manually scaling and/or centering data for **supervised learning**, you must:  

* Perform scaling and centering on your **training data**,
* Save the **centering and scaling parameters** for each feature, and
* Apply the training set-derived centering and scaling parameters to the **test set** *prior to prediction/inference*.
:::

A common mistake is to either scale training and testing data together in the beginning, or scale them independently.  

### Normalization

**Normalization** has different meanings in different contexts; in the context of a numeric variable it usually refers to converting to a 0-1 range.

Let's write a simple function to achieve this:

```{r}
normalize <- function(x) {
  .min <- min(x, na.rm = TRUE)
  (x - .min) / max(x - .min, na.rm = TRUE)
}
```

```{r}
x <- rnorm(20, 13, 1.4)
x
```

```{r}
x_normalized <- normalize(x)
x_normalized
min(x_normalized)
max(x_normalized)
```

Note that it is easy to make the `normalize()` function more general, by adding `lo` and `hi` arguments to convert to any range:

```{r}
dr <- function(x, lo = 0, hi = 1) {
    .min <- min(x, na.rm = TRUE)
   (x - .min) / max(x - .min, na.rm = TRUE) * (hi - lo) + lo
  }
```

```{r}
dr(x, -1, 1)
```

### Log-transform with `log()`

```{r include = FALSE}
set.seed(2021)
v <- rnorm(1000)
vs <- scale(v)
vp <- (vs - min(vs))
x <- as.numeric(exp(vp))
```

For the following example, `x` is an unknown feature in a new dataset we were 
just given.

We start by plotting its distribution:

```{r}
mplot3_x(x)
```

We can see it is skewed right. A log transform can help here:

```{r}
mplot3_x(log(x))
```

### Data binning with `cut()`

A different approach for the above variable might be to bin it.  
Let's look at a few different ways to bin continuous data.

#### Evenly-spaced interval

`cut()` allows us to bin a numeric variable into evenly-spaced intervals.  
The `breaks` argument defines the number of intervals:

```{r}
x_cut4 <- cut(x, breaks = 4)
head(x_cut4)
table(x_cut4)
```

::: callout-important
**Interval Notation**

`[3, 9)` represents the interval of [real numbers](https://en.wikipedia.org/wiki/Real_number) 
between 3 and 9, **including** 3 and **excluding** 9.
:::

Because the data is so skewed, equal intervals are not helpful in this case. The majority of the data points get grouped into a single bin.

Let's visualize the cuts:

```{r}
xcuts5 <- seq(min(x), max(x), length.out = 5)
xcuts5
```

```{r}
mplot3_x(x, par.reset = FALSE)
# plot(density(x)) # in base R
abline(v = xcuts5, col = "red", lwd = 1.5)
```

[Note: We used `par.reset = FALSE` to stop `mplot3_x()` from resetting its custom `par()` settings so that we can continue adding elements to the same plot, in this case with the `abline()` command.]

#### Quantile cuts

Instead of evenly-spaced intervals, we can get quantiles with `quantile()`. We ask for 5 quantiles using the `length.out` argument, which corresponds to 4 intervals:

```{r}
xquants5 <- quantile(x, seq(0, 1, length.out = 5))
xquants5 <- quantile(x, seq(0, 1, length.out = 5))
mplot3_x(x, par.reset = F)
# plot(density(x)) # in base R
abline(v = xquants5, col = "green", lwd = 1.5)
```

The `breaks` argument of `cut()` allows us to pass either an integer to define the number of evenly-spaced breaks, or a numeric vector defining the position of breaks.

We can therefore pass the quantile values as break points.

Since the quantile values begin at the lowest value in the data, we need to define 
`include.lowest = TRUE` so that the first interval is inclusive of the lowest value:

```{r}
x_cutq4 <- cut(x, breaks = xquants5, include.lowest = TRUE)
table(x_cutq4)
```

With quantile cuts, each bin contains roughly the same number of observations (+/- 1).  

## Categorical variables

Many algorithms (or their implementations) do not directly support categorical variables. To use 
them, you must therefore convert all categorical variables to some type of numerical encoding.

### Integer encoding

If the categorical data is ordinal, you can simply convert it to integers.  
For example, the following **ordered factor**:

```{r}
brightness <- factor(c("bright", "brightest", "darkest",
                        "bright", "dark", "dim", "dark"),
                      levels = c("darkest", "dark", "dim", "bright", "brightest"),
                      ordered = TRUE)
brightness
```

can be directly coerced to an integer:

```{r}
as.integer(brightness)
```

### One-hot encoding

When categorical features are **not** ordinal, and your algorithm cannot handle them directly, you 
can one-hot encode them. In one-hot encoding, each categorical feature is converted to k binary 
features, where k = number of unique values in the input, such that only one feature has the value 1 
per case. This is similar to creating dummy variables in statistics, with the difference that dummy 
variables create `k - 1` new variables.

```{r}
set.seed(21)
admission_reasons <- c("plannedSurgery", "emergencySurgery", "medical")
admission <- sample(admission_reasons, 12, T)
admission
```

Multiple packages include functions that perform one-hot encoding. It's a simple operation and we don't necessarily need to install a large package with many dependencies.

Let's write a simple function to perform one-hot encoding. Note, you may have heard that for loops can be slow in R, but that depends on the operations performed. Here, we loop over an integer matrix and it is plenty fast.

```{r}
onehot <- function(x, xname = NULL) {
  if (is.null(xname)) xname <- deparse(substitute(x))
  x <- factor(x)
  .levels <- levels(x)      # Get factor levels
  ncases <- NROW(x)         # Get number of cases
  index <- as.integer(x)    # Convert levels to integer
  oh <- matrix(0, ncases, length(.levels))   # Initialize zeros matrix
  colnames(oh) <- paste(xname, .levels, sep = "_")  # Name columns by levels
  for (i in seq(ncases)) oh[i, index[i]] <- 1  # Assign "1" to appropriate level
  oh
}
```

Let's apply our new function to the admission vector:

```{r}
onehot(admission)
```

Note: `deparse(substitute(x))` above is used to automatically get the name of the input object (in this case "admission"). This is similar to how many of R's internal functions (e.g. `plot()`) get the names of input objects.
