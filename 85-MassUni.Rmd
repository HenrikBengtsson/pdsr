# Mass-univariate testing {#massuni}

```{r echo = FALSE}
knitr::opts_chunk$set(fig.width = 4.5, fig.height = 4.5,
                      comment = NA, cache = TRUE) 
options(rt.theme = "lightgrid")
options(rt.fit.theme = "lightgrid")
```

```{r, comment="", results="asis", echo=FALSE}
old.hooks <- fansi::set_knit_hooks(knitr::knit_hooks)
options(crayon.enabled = TRUE)
```

```{r echo = FALSE}
library(rtemis)
```

## Data
First, some synthetic data:
```{r}
set.seed(2020)
n_col <- 100
n_row <- 1000
x <- as.data.frame(lapply(seq(n_col), function(i) rnorm(n_row)),
                   col.names = paste0("Feature_", seq(n_col)))
dim(x)
y <- .7 + x[, 10] + .3 * x[, 20] + 1.3 * x[, 30] + x[, 50] + rnorm(500)
```

## Mass-lm
Let's fit a linear model regressing y on each column of x using `lm`:
```{r}
mod.xy.massuni <- lapply(seq(x), function(i) lm(y ~ x[, i]))
length(mod.xy.massuni)
names(mod.xy.massuni) <- paste0("mod", seq(x))
```

To extract p-values for each model, we must find where exactly to look.  
Let's look into the first model:
```{r}
(ms1 <- summary(mod.xy.massuni$mod1))
ms1$coefficients
```

The p-values for each feature is stored in row 1, column 4 fo the coefficients matrix. Let's extract all of them:
```{r}
mod.xy.massuni.pvals <- sapply(mod.xy.massuni, function(i) summary(i)$coefficients[2, 4])
```
Let's see which variable are significant at the 0.05:
```{r}
which(mod.xy.massuni.pvals < .05)
```
...and which are significant at the 0.01 level:
```{r}
which(mod.xy.massuni.pvals < .01)
```

## Multiple comparison correction
But, we need to control for multiple comparisons!  
We use R's `p.adjust` command. It adjusts a vector of p-values to account for multiple comparisons using one of many different methods. The default, and recommended, is the [Holm method](https://en.wikipedia.org/wiki/Holm%E2%80%93Bonferroni_method). It ensures that `FWER < Î±`, i.e. controls the [family-wise error rate](https://en.wikipedia.org/wiki/Family-wise_error_rate), a.k.a. the probability of making one or more false discoveries (Type I errors) 
```{r}
mod.xy.massuni.pvals.holm_adjusted <- p.adjust(mod.xy.massuni.pvals)
```

Now, let's see which features' p-values survive the magical threshold:
```{r}
which(mod.xy.massuni.pvals.holm_adjusted < .05)
```
The are indeed the correct features (!)
