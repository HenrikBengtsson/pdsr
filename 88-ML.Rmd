# Introduction to Predictive Modeling {#ml}

```{r echo = FALSE}
knitr::opts_chunk$set(fig.width = 5, fig.height = 5,
                      comment = NA, cache = TRUE)
options(rt.theme = "lightgrid")
options(rt.fit.theme = "lightgrid")
```

```{r, comment="", results="asis", echo=FALSE}
old.hooks <- fansi::set_knit_hooks(knitr::knit_hooks)
options(crayon.enabled = TRUE)
```

```{r lib}
library(rtemis)
```

## Data Input for Supervised Learning
All __rtemis__ supervised learning functions begin with `s.` ("supervised").  
They accept the same first four arguments:  
`x`, `y`, `x.test`, `y.test`  
but are flexible and allow you to also provide combined (x, y) and (x.test, y.test) data frames, as explained below.

### Scenario 1 (`x.train, y.train, x.test, y.test`)
In the most straightforward case, provide each featureset and outcome individually:  

* `x`: Training set features
* `y`: Training set outcome
* `x.test`: Testing set features (Optional)
* `y.test`: Testing set outcome (Optional)

```{r}
x <- rnormmat(200, 10, seed = 2019)
w <- rnorm(10)
y <- x %*% w + rnorm(200)
res <- resample(y, seed = 2020)
x.train <- x[res$Subsample_1, ]
x.test <- x[-res$Subsample_1, ]
y.train <- y[res$Subsample_1]
y.test <- y[-res$Subsample_1]
```

```{r}
mod.glm <- s.GLM(x.train, y.train, x.test, y.test)
```

### Scenario 2: (`x.train, x.test`)
You can provide training and testing sets as a single data.frame each, where the last column is the outcome. Now `x` is the full training data and `y` the full testing data:  

* `x`: data.frame(x.train, y.train)
* `y`: data.frame(x.test, y.test)

```{r}
x <- rnormmat(200, 10, seed = 2019)
w <- rnorm(10)
y <- x %*% w + rnorm(200)
dat <- data.frame(x, y)
res <- resample(dat, seed = 2020)
dat.train <- dat[res$Subsample_1, ]
dat.test <- dat[-res$Subsample_1, ]
```

```{r}
mod.glm <- s.GLM(dat.train, dat.test)
```

The `dataPrepare` function will check data dimensions and determine whether data was input as separate feature and outcome sets or combined and ensure the correct number of cases and features was provided.  

In either scenario, Regression will be performed if the outcome is numeric and Classification if the outcome is a factor.


## Regression

### Check Data
```{r synth reg data}
x <- rnormmat(500, 50, seed = 2019)
w <- rnorm(50)
y <- x %*% w + rnorm(500)
dat <- data.frame(x, y)
res <- resample(dat)
dat.train <- dat[res$Subsample_1, ]
dat.test <- dat[-res$Subsample_1, ]
```

```{r}
checkData(x)
```


### Single Model
```{r}
mod <- s.GLM(dat.train, dat.test)
```

### Crossvalidated Model
```{r}
mod <- elevate(dat, mod = "glm")
```

Use the `describe` function to get a summary in (plain) English:
```{r}
mod$describe()
```

```{r, fig.width = 5, fig.height = 5.5}
mod$plot()
```


## Classification

### Check Data
```{r}
data(Sonar, package = 'mlbench')
checkData(Sonar)
res <- resample(Sonar)
sonar.train <- Sonar[res$Subsample_1, ]
sonar.test <- Sonar[-res$Subsample_1, ]
```

### Single model
```{r}
mod <- s.RANGER(sonar.train, sonar.test)
```


### Crossvalidated Model
```{r}
mod <- elevate(Sonar)
```

```{r}
mod$describe()
```

```{r, fig.width = 5, fig.height = 5.5}
mod$plot()
```

```{r}
mod$plotROC()
```

```{r}
mod$plotPR()
```

## __rtemis__ documentation
For more information on using __rtemis__, see the [documentation](https://rtemis.netlify.com)